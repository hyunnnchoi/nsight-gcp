apiVersion: kubeflow.org/v1
kind: TFJob
metadata:
  name: t8-id0-imagenet-resnet50-sync-batch16
spec:
  runPolicy:
    cleanPodPolicy: None
  tfReplicaSpecs:
    Worker:
      replicas: 2
      template:
        spec:
          containers:
          - name: tensorflow
            command: ["/bin/sh", "-c"]
            securityContext:
              privileged: true
            args:
              - cd /tf_cnn_benchmarks/NVML;
                make;
                JOB=`python /tf_cnn_benchmarks/job_name.py`;
                CONTROLLER_HOST=`python -c "import os, json; tf_config = json.loads(os.environ.get('TF_CONFIG') or '{}'); cluster_config = tf_config.get('cluster', {}); controller_host = cluster_config.get('controller'); print(','.join(controller_host))"`;
                mkdir -p /result/t8_id0_imagenet_resnet50_sync_batch16;
                top -d 0.1 -b | grep tf_cnn > /result/t8_id0_imagenet_resnet50_sync_batch16/t8_id0_imagenet_resnet50_sync_batch16_${JOB}_cpu.txt &
                echo "t8_id0_imagenet_resnet50_sync_batch16" > /tf_cnn_benchmarks/model.txt;
                STARTTIME=`date "+%H:%M:%S.%N"`;
                echo "$STARTTIME" > /result/t8_id0_imagenet_resnet50_sync_batch16/t8_id0_imagenet_resnet50_sync_batch16_${JOB}_start_time.txt;
                nsys profile --duration=600 -o /result/t8_id0_imagenet_resnet50_sync_batch16/t8_id0_imagenet_resnet50_sync_batch16_${JOB} --force-overwrite true python /tf_cnn_benchmarks/tf_cnn_benchmarks.py --variable_update=parameter_server --model=resnet50 --data_name=imagenet --display_every=1 --batch_size=16 --cross_replica_sync=true --num_batches=10 --num_warmup_batches=0;
                ENDTIME=`date "+%H:%M:%S.%N"`;
                echo "$ENDTIME" > /result/t8_id0_imagenet_resnet50_sync_batch16/t8_id0_imagenet_resnet50_sync_batch16_${JOB}_end_time.txt
            ports:
            - containerPort: 2222
              name: tfjob-port
            image: potato4332/tf2-gpu-docker:0.4.0
            imagePullPolicy: IfNotPresent
            resources:
              requests:
                cpu: 1
              limits:
                cpu: 5
                nvidia.com/gpu: 1
            volumeMounts:
            - mountPath: /result
              name: tfjob-data
            - mountPath: /dev/shm
              name: shmdir
            - mountPath: /host_output
              name: host-output
          topologySpreadConstraints:
          - maxSkew: 1
            topologyKey: kubernetes.io/hostname
            whenUnsatisfiable: DoNotSchedule
            labelSelector:
              matchLabels:
                app: Worker
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                - matchExpressions:
                  - key: kubernetes.io/hostname
                    operator: In
                    values:
                    - xsailor-worker6
                    - xsailor-worker7
          volumes:
          - name: tfjob-data
            persistentVolumeClaim:
              claimName: tfjob-data-volume-claim
          - name: shmdir
            emptyDir:
              medium: Memory
              sizeLimit: "8G"
          - name: host-output
            hostPath:
              path: /home/jhlee21/hmchoi
              type: DirectoryOrCreate
    PS:
      replicas: 2
      template:
        spec:
          containers:
          - name: tensorflow
            command: ["/bin/sh", "-c"]
            args:
              - JOB=`python /tf_cnn_benchmarks/job_name.py`;
                CONTROLLER_HOST=`python -c "import os, json; tf_config = json.loads(os.environ.get('TF_CONFIG') or '{}'); cluster_config = tf_config.get('cluster', {}); controller_host = cluster_config.get('controller'); print(','.join(controller_host))"`;
                mkdir -p /result/t8_id0_imagenet_resnet50_sync_batch16;
                echo "t8_id0-imagenet-resnet50-sync-batch16" > /tf_cnn_benchmarks/model.txt;
                top -d 0.1 -b | grep tf_cnn > /result/t8_id0_imagenet_resnet50_sync_batch16/t8_id0_imagenet_resnet50_sync_batch16_${JOB}_cpu.txt &
                python /tf_cnn_benchmarks/tf_cnn_benchmarks.py --variable_update=parameter_server --model=resnet50 --data_name=imagenet --display_every=1 --batch_size=16 --cross_replica_sync=true --num_batches=10 --num_warmup_batches=0;
                ENDTIME=`date "+%H:%M:%S.%N"`;
                echo "$ENDTIME" > /result/t8_id0-imagenet-resnet50-sync_batch16/t8_id0_imagenet_resnet50_sync_batch16_${JOB}_end_time.txt
            ports:
            - containerPort: 2222
              name: tfjob-port
            image: potato4332/tf2-cpu-docker:0.4.0
            imagePullPolicy: IfNotPresent
            resources:
              requests:
                cpu: 1
              limits:
                cpu: 5
            volumeMounts:
            - mountPath: /result
              name: tfjob-data
            - mountPath: /dev/shm
              name: shmdir
            - mountPath: /host_output
              name: host-output
          topologySpreadConstraints:
          - maxSkew: 1
            topologyKey: kubernetes.io/hostname
            whenUnsatisfiable: DoNotSchedule
            labelSelector:
              matchLabels:
                app: PS
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                - matchExpressions:
                  - key: kubernetes.io/hostname
                    operator: In
                    values:
                    - xsailor-worker6
                    - xsailor-worker7
          volumes:
          - name: tfjob-data
            persistentVolumeClaim:
              claimName: tfjob-data-volume-claim
          - name: shmdir
            emptyDir:
              medium: Memory
              sizeLimit: "8G"
          - name: host-output
            hostPath:
              path: /home/jhlee21/hmchoi
              type: DirectoryOrCreate
